{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed-based FC\n",
    "\n",
    "\n",
    "**Resources**\n",
    "\n",
    "[Nilearn 9.4.6. Producing single subject maps of seed-to-voxel correlation](https://nilearn.github.io/auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html#sphx-glr-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py)\n",
    "\n",
    "[Nilearn: 9.5.4. Default Mode Network extraction of AHDH dataset](https://nilearn.github.io/auto_examples/04_glm_first_level/plot_adhd_dmn.html)\n",
    "\n",
    ":::{note}\n",
    "HC coordinates from Sherman (2015): <br>\n",
    "'Analyses focused on a priori defined region of the anterior hippocampus (MNI coordinates: x = -21, y = -9, z = -15) because of its importance to retrieval of relational memory (Giovanello et al., 2009) and sensitivity to prior sleep physiology (Mander et al., 2013a).'\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nilearn import plotting, image, input_data\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, FirstLevelModel\n",
    "from nilearn.plotting import plot_design_matrix, plot_contrast_matrix\n",
    "\n",
    "tr = 1.5  \n",
    "n_scans = 164 * 3\n",
    "frame_times = np.arange(n_scans) * tr  \n",
    "hc_coords = [(-21, -9, -15)]\n",
    "runs = ['1', '2', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30004/func/sub-30004_task-MemMatch1_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30004/func/sub-30004_task-MemMatch2_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30004/func/sub-30004_task-MemMatch3_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30008/func/sub-30008_task-MemMatch1_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30008/func/sub-30008_task-MemMatch2_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_files = sorted(glob.glob('/Volumes/psybrain/ADM/derivatives/fmriprep/sub-*/func/sub-*_task-MemMatch[1-3]_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'))\n",
    "func_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30004/func/sub-30004_task-MemMatch1_run-01_desc-confounds_regressors.tsv',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30004/func/sub-30004_task-MemMatch2_run-01_desc-confounds_regressors.tsv',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30004/func/sub-30004_task-MemMatch3_run-01_desc-confounds_regressors.tsv',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30008/func/sub-30008_task-MemMatch1_run-01_desc-confounds_regressors.tsv',\n",
       " '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-30008/func/sub-30008_task-MemMatch2_run-01_desc-confounds_regressors.tsv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_files = sorted(glob.glob('/Volumes/psybrain/ADM/derivatives/fmriprep/sub-*/func/sub-*_task-MemMatch[1-3]_run-01_desc-confounds_regressors.tsv'))\n",
    "conf_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30004', '30008', '30009', '30012', '30015'], dtype='<U5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = np.unique([ func_file.split('sub-')[1][:5] for func_file in func_files])\n",
    "np.savetxt('/Volumes/schnyer/Megan/adm_mem-fc/analysis/seed-based_fc/subjects.txt', subjects, fmt = '%s')\n",
    "subjects[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First level GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hrf_model = 'spm + derivative'\n",
    "selected_confounds = ['a_comp_cor_00', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'motion_outlier_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40601\n",
      "[Errno 2] File b'/Volumes/psybrain/ADM/derivatives/fmriprep/sub-40601/func/sub-40601_task-MemMatch3_run-01_desc-confounds_regressors.tsv' does not exist: b'/Volumes/psybrain/ADM/derivatives/fmriprep/sub-40601/func/sub-40601_task-MemMatch3_run-01_desc-confounds_regressors.tsv'\n",
      "40768\n",
      "[Errno 2] File b'/Volumes/psybrain/ADM/derivatives/fmriprep/sub-40768/func/sub-40768_task-MemMatch2_run-01_desc-confounds_regressors.tsv' does not exist: b'/Volumes/psybrain/ADM/derivatives/fmriprep/sub-40768/func/sub-40768_task-MemMatch2_run-01_desc-confounds_regressors.tsv'\n",
      "40779\n",
      "[Errno 2] File b'/Volumes/psybrain/ADM/derivatives/fmriprep/sub-40779/func/sub-40779_task-MemMatch3_run-01_desc-confounds_regressors.tsv' does not exist: b'/Volumes/psybrain/ADM/derivatives/fmriprep/sub-40779/func/sub-40779_task-MemMatch3_run-01_desc-confounds_regressors.tsv'\n",
      "40968\n",
      "No columns to parse from file\n"
     ]
    }
   ],
   "source": [
    "# for subject in subjects:\n",
    "    \n",
    "#     for run in runs:\n",
    "    \n",
    "#         try:\n",
    "#             confounds_ = pd.read_csv('/Volumes/psybrain/ADM/derivatives/fmriprep/sub-%s/func/sub-%s_task-MemMatch%s_run-01_desc-confounds_regressors.tsv' % (subject, subject, run), \n",
    "#                                             sep = '\\t')\n",
    "#             confounds_['motion_outlier_00'] = np.where(confounds_['framewise_displacement'] > 0.20, 1, 0)\n",
    "#             confounds_.to_csv('/Volumes/psybrain/ADM/derivatives/fmriprep/sub-%s/func/sub-%s_task-MemMatch%s_run-01_desc-confounds_regressors.tsv' % (subject, subject, run), sep='\\t', index=False)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(subject)\n",
    "#             print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_masker = input_data.NiftiSpheresMasker(\n",
    "    hc_coords, radius=8,\n",
    "    mask_img='/usr/local/fsl/data/standard/MNI152_T1_1mm_brain_mask.nii.gz',\n",
    "    detrend=True, \n",
    "    standardize=True,\n",
    "    low_pass=0.08, high_pass=0.008, \n",
    "    t_r=tr,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=1)\n",
    "\n",
    "brain_masker = input_data.NiftiMasker(\n",
    "    mask_img='/usr/local/fsl/data/standard/MNI152_T1_1mm_brain_mask.nii.gz',\n",
    "    smoothing_fwhm=6,\n",
    "    detrend=True, \n",
    "    standardize=True,\n",
    "    low_pass=0.08, high_pass=0.008, \n",
    "    t_r=tr,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30004\n",
      "1 30008\n",
      "2 30009\n",
      "3 30012\n",
      "4 30015\n",
      "5 30019\n",
      "6 30020\n",
      "7 30023\n",
      "8 30040\n",
      "9 30057\n",
      "10 30064\n",
      "11 30066\n",
      "12 30069\n",
      "13 30074\n",
      "14 30085\n",
      "15 30088\n",
      "16 30090\n",
      "17 30091\n",
      "18 30095\n",
      "19 30096\n",
      "20 30105\n",
      "21 30116\n",
      "22 30118\n",
      "23 30119\n",
      "24 30128\n",
      "25 30181\n",
      "26 30217\n",
      "27 30227\n",
      "28 30236\n",
      "29 30242\n",
      "30 30255\n",
      "31 30274\n",
      "32 30283\n",
      "33 30295\n",
      "34 30330\n",
      "35 30346\n",
      "36 30376\n",
      "37 30395\n",
      "38 30400\n",
      "39 30403\n",
      "40 30412\n",
      "41 30426\n",
      "42 30432\n",
      "43 30466\n",
      "44 30469\n",
      "45 30476\n",
      "46 30478\n",
      "47 30568\n",
      "48 30570\n",
      "49 30581\n",
      "50 30584\n",
      "51 30588\n",
      "52 40160\n",
      "53 40170\n",
      "54 40175\n",
      "55 40288\n",
      "56 40351\n",
      "57 40490\n",
      "58 40496\n",
      "59 40500\n",
      "60 40512\n",
      "61 40515\n",
      "62 40516\n",
      "63 40519\n",
      "64 40520\n",
      "65 40522\n",
      "66 40524\n",
      "67 40547\n",
      "68 40550\n",
      "69 40564\n",
      "70 40601\n",
      "71 40608\n",
      "72 40615\n",
      "73 40619\n",
      "74 40623\n",
      "75 40624\n",
      "76 40629\n",
      "77 40638\n",
      "78 40649\n",
      "79 40650\n",
      "80 40655\n",
      "81 40656\n",
      "82 40658\n",
      "83 40664\n",
      "84 40665\n",
      "85 40668\n",
      "86 40672\n",
      "87 40685\n",
      "88 40694\n",
      "89 40720\n",
      "90 40728\n",
      "91 40730\n",
      "92 40738\n",
      "93 40743\n",
      "94 40750\n",
      "95 40758\n",
      "96 40767\n",
      "97 40768\n",
      "98 40769\n",
      "99 40773\n",
      "100 40777\n",
      "101 40778\n",
      "102 40779\n",
      "103 40782\n",
      "104 40784\n",
      "105 40796\n",
      "106 40803\n",
      "107 40855\n",
      "108 40861\n",
      "109 40930\n",
      "110 40961\n",
      "111 40968\n"
     ]
    }
   ],
   "source": [
    "for i, subject in enumerate(subjects):\n",
    "    \n",
    "    print(i, subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: 30295\n",
      "concatenated functional image dimensions:  (97, 115, 97, 492)\n",
      "cue functional image dimensions:  (97, 115, 97, 492)\n",
      "extract time series from hc roi\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.base_masker.filter_and_extract...\n",
      "filter_and_extract(<nibabel.nifti1.Nifti1Image object at 0x12dd278d0>, <nilearn.input_data.nifti_spheres_masker._ExtractionFunctor object at 0x12d3e8f50>, \n",
      "{ 'allow_overlap': False,\n",
      "  'detrend': True,\n",
      "  'dtype': None,\n",
      "  'high_pass': 0.008,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': 0.08,\n",
      "  'mask_img': '/usr/local/fsl/data/standard/MNI152_T1_1mm_brain_mask.nii.gz',\n",
      "  'radius': 8,\n",
      "  'seeds': [(-21, -9, -15)],\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': True,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 1.5}, confounds=[      a_comp_cor_00       trans_x       trans_y   trans_z     rot_x     rot_y  \\\n",
      "0         0.000000 -1.041660e-11 -3.891780e-10  0.000000  0.000000 -0.000000   \n",
      "1        -0.087429  9.735280e-03 -1.459730e-02  0.011279  0.000500  0.000347   \n",
      "2        -0.102330  1.254810e-02  2.104130e-02  0.016969  0.000019  0.000364   \n",
      "3        -0.101215  1.313700e-02 -1.558150e-02  0.046614  0.000336  0.000211   \n",
      "4        -0.103547  1.297680e-02 -9.333380e-03  0.022465  0.000422  0.000287   \n",
      "5        -0.063075  1.343970e-02 -2.732080e-02  0.026755  0.000483  0.000287   \n",
      "6        -0.058633  1.609400e-02 -1.069100e-02 -0.005385  0.000587  0.000287   \n",
      "7        -0.047247  1.609530e-02 -4.041050e-03  0.026706  ..., sample_mask=None, dtype=None, memory=Memory(location=nilearn_cache/joblib), memory_level=1, verbose=1)\n",
      "[NiftiSpheresMasker.transform_single_imgs] Loading data from Nifti1Image('/Volumes/schnyer/Megan/adm_mem-fc/analysis/seed-based_fc/sub-30295_task-MemMatch_bold.nii.gz')\n",
      "[NiftiSpheresMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiSpheresMasker.transform_single_imgs] Cleaning extracted signals\n",
      "______________________________________________filter_and_extract - 19.0s, 0.3min\n",
      "extract time series from brain\n",
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.image.resampling.resample_img...\n",
      "resample_img(<nibabel.nifti1.Nifti1Image object at 0x12df0b490>, target_affine=None, target_shape=None, copy=False, interpolation='nearest')\n",
      "_____________________________________________________resample_img - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.nifti_masker.filter_and_mask...\n",
      "filter_and_mask(<nibabel.nifti1.Nifti1Image object at 0x12dd278d0>, <nibabel.nifti1.Nifti1Image object at 0x12df0b490>, { 'detrend': True,\n",
      "  'dtype': None,\n",
      "  'high_pass': 0.008,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': 0.08,\n",
      "  'reports': True,\n",
      "  'runs': None,\n",
      "  'smoothing_fwhm': 6,\n",
      "  'standardize': True,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 1.5,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=1, memory=Memory(location=nilearn_cache/joblib), verbose=1, confounds=[      a_comp_cor_00       trans_x       trans_y   trans_z     rot_x     rot_y  \\\n",
      "0         0.000000 -1.041660e-11 -3.891780e-10  0.000000  0.000000 -0.000000   \n",
      "1        -0.087429  9.735280e-03 -1.459730e-02  0.011279  0.000500  0.000347   \n",
      "2        -0.102330  1.254810e-02  2.104130e-02  0.016969  0.000019  0.000364   \n",
      "3        -0.101215  1.313700e-02 -1.558150e-02  0.046614  0.000336  0.000211   \n",
      "4        -0.103547  1.297680e-02 -9.333380e-03  0.022465  0.000422  0.000287   \n",
      "5        -0.063075  1.343970e-02 -2.732080e-02  0.026755  0.000483  0.000287   \n",
      "6        -0.058633  1.609400e-02 -1.069100e-02 -0.005385  0.000587  0.000287   \n",
      "7        -0.047247  1.609530e-02 -4.041050e-03  0.026706  ..., sample_mask=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/Volumes/schnyer/Megan/adm_mem-fc/analysis/seed-based_fc/sub-30295_task-MemMatch_bold.nii.gz')\n",
      "[NiftiMasker.transform_single_imgs] Resampling images\n"
     ]
    }
   ],
   "source": [
    "dsn = pd.DataFrame(frame_times, columns = ['frame_times'])\n",
    "i = 0\n",
    "\n",
    "for subject in sorted(subjects[33:]):\n",
    "    \n",
    "    try:\n",
    "        print('subject: %s' % subject)\n",
    "\n",
    "        confounds_concat = pd.DataFrame()\n",
    "        func_files = []\n",
    "        func_img = []\n",
    "        func_img_cue = []\n",
    "\n",
    "        for run in runs:\n",
    "\n",
    "            # concatenate 3 runs confounds files\n",
    "            confounds = pd.read_csv('/Volumes/psybrain/ADM/derivatives/fmriprep/sub-%s/func/sub-%s_task-MemMatch%s_run-01_desc-confounds_regressors.tsv' % (subject, subject, run), \n",
    "                                    sep = '\\t')[selected_confounds]\n",
    "            confounds_concat = confounds_concat.append(confounds).reset_index(drop=True)\n",
    "\n",
    "            # get all 3 func file names\n",
    "            func_file = '/Volumes/psybrain/ADM/derivatives/fmriprep/sub-%s/func/sub-%s_task-MemMatch%s_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz' % (subject, subject, run)\n",
    "            func_files = func_files + [func_file]\n",
    "\n",
    "        # concatenate 3 runs of func images\n",
    "        func_img = image.concat_imgs(func_files)\n",
    "        print('concatenated functional image dimensions: ', func_img.shape)\n",
    "\n",
    "        func_img_cue = func_img \n",
    "        func_img_cue.to_filename(\n",
    "            '/Volumes/schnyer/Megan/adm_mem-fc/analysis/seed-based_fc/sub-%s_task-MemMatch_bold.nii.gz' %\n",
    "        (subject))\n",
    "        print('cue functional image dimensions: ', func_img_cue.shape)\n",
    "\n",
    "        print('extract time series from hc roi')\n",
    "        seed_time_series = seed_masker.fit_transform(func_img_cue, confounds=confounds_concat)\n",
    "\n",
    "        print('extract time series from brain')\n",
    "        brain_time_series = brain_masker.fit_transform(func_img_cue, confounds=confounds_concat)\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"Seed time series shape: (%s, %s)\" % seed_time_series.shape)\n",
    "            print(\"Brain time series shape: (%s, %s)\" % brain_time_series.shape)\n",
    "\n",
    "        plt.plot(seed_time_series)\n",
    "        plt.title('sub-%s, Seed Time Series (Hippocampus)' % subject)\n",
    "        plt.xlabel('Scan number')\n",
    "        plt.ylabel('Normalized signal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        seed_to_voxel_correlations = (np.dot(brain_time_series.T, seed_time_series) /\n",
    "                              seed_time_series.shape[0])\n",
    "\n",
    "        seed_to_voxel_correlations_img = brain_masker.inverse_transform(seed_to_voxel_correlations.T)\n",
    "\n",
    "        seed_to_voxel_correlations_img.to_filename(\n",
    "            '/Volumes/schnyer/Megan/adm_mem-fc/analysis/seed-based_fc/sub-%s_task-MemMatch_seed-based-hc_correlation_zstat.nii.gz' %\n",
    "        (subject))\n",
    "\n",
    "        display = plotting.plot_stat_map(seed_to_voxel_correlations_img,\n",
    "                                         threshold=0.5, vmax=1,\n",
    "                                         cut_coords=hc_coords[0],\n",
    "                                         title=\"sub-%s Seed-to-voxel correlation (HC seed)\" % subject\n",
    "                                         )\n",
    "\n",
    "        plt.show()\n",
    "        display.savefig('/Volumes/schnyer/Megan/adm_mem-fc/analysis/seed-based_fc/sub-%s_task-MemMatch_seed-based-hc_correlation_zstat.png' %\n",
    "                       (subject))\n",
    "        \n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_subs = []\n",
    "fd_stats = pd.DataFrame()\n",
    "tr_perc = .2\n",
    "\n",
    "for file in sorted(conf_files):\n",
    "    \n",
    "    subject = file.split('sub-')[1][:5]\n",
    "    run = file.split('MemMatch')[1][0:1]\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        conf_ = pd.read_csv(file, sep='\\t')\n",
    "        \n",
    "        fd_mean = conf_['framewise_displacement'].mean()\n",
    "        fd_perc = (conf_['framewise_displacement'] > 0.50).sum() / len(conf_['framewise_displacement'])\n",
    "        fd_stats = fd_stats.append({'subject': subject,\n",
    "                                    'run': run,\n",
    "                                    'fd_mean': fd_mean,\n",
    "                                   'fd_perc': fd_perc}, ignore_index=True)\n",
    "        \n",
    "        if ((fd_mean > 0.50) or (fd_perc > tr_perc)):\n",
    "            drop_subs.append([subject, run, 'fd_mean= %.2f' % fd_mean, 'fd_perc = %.2f' % fd_perc])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(subject, e)\n",
    "        drop_subs.append([subject, run, e])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_subs_ = [x[0] for x in drop_subs]\n",
    "drop_subs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_stats['fd_mean'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_stats['fd_perc'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_files = glob.glob('/Volumes/schnyer/Megan/adm_mem-fc/analysis/seed-based_fc/sub-*_task-MemMatch_seed-based-hc_correlation_zstat.nii.gz')\n",
    "print(len(cor_files))\n",
    "\n",
    "cor_files = [file for file in cor_files if file.split('sub-')[1][:5] not in drop_subs_]\n",
    "print(len(cor_files))\n",
    "ya_files = [file for file in cor_files if 'sub-3' in file]\n",
    "print('ya ', len(ya_files))\n",
    "oa_files = [file for file in cor_files if 'sub-4' in file]\n",
    "print('oa ', len(oa_files))\n",
    "\n",
    "# dsn_mat2 = pd.DataFrame([1] * len(cor_files), columns = ['intercept'])\n",
    "dsn_mat2 = pd.DataFrame([1] * len(ya_files) + [-1] * len(oa_files), columns=['age group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8.0).fit(\n",
    "    cor_files, design_matrix=dsn_mat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = second_level_model.compute_contrast(second_level_contrast=[1], output_type='z_score')\n",
    "\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(z_map, title='Raw z map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm import threshold_stats_img\n",
    "thresholded_map1, threshold1 = threshold_stats_img(\n",
    "    z_map,\n",
    "    alpha=.001,\n",
    "    height_control='fpr',\n",
    "    cluster_threshold=10,\n",
    "    two_sided=True,\n",
    ")\n",
    "plotting.plot_stat_map(\n",
    "    thresholded_map1, cut_coords=display.cut_coords, threshold=threshold1,\n",
    "    title='Thresholded z map, fpr <.001, clusters > 10 voxels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_map2, threshold2 = threshold_stats_img(\n",
    "    z_map, alpha=.05, height_control='fdr')\n",
    "print('The FDR=.05 threshold is %.3g' % threshold2)\n",
    "\n",
    "\n",
    "plotting.plot_stat_map(thresholded_map2, cut_coords=display.cut_coords,\n",
    "                       title='Thresholded z map, expected fdr = .05',\n",
    "                       threshold=threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_map3, threshold3 = threshold_stats_img(\n",
    "    z_map, alpha=.05, height_control='bonferroni')\n",
    "print('The p<.05 Bonferroni-corrected threshold is %.3g' % threshold3)\n",
    "\n",
    "plotting.plot_stat_map(thresholded_map3, cut_coords=display.cut_coords,\n",
    "                       title='Thresholded z map, expected fwer < .05',\n",
    "                       threshold=threshold3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
